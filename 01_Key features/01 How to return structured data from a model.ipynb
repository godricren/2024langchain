{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How to return structured data from a model\n",
    "\n",
    "It is often useful to have a model return output that matches a specific schema. One common use-case is extracting data from text to inert into a database or use with some other downstream system. This guide covers a few strategies for getting structured outputs from a model.\n",
    "\n",
    "## The `.with_structured_output()` method\n",
    "\n",
    "This is the easies and most reliable way to get structured outputs. `.with_structured_output()` is implemented for models that provide native APIs for structuring outputs, like tool/function calling or JSON mode, and use of these capabilities under the hood.\n",
    "\n",
    "This method takes a schema as input which specifies the names, types, and descriptions of the desired output attributes. The method returns a model-like Runnable, except that instead of outputting strings or Messages it outputs objects corresponding to the given schema. The schema can be specified as a TypedDict class, JSON Schema or Pydantic class. If TypeDict or JSON Schema are used then a dictionary will be returned by the Runnable, and if Pydantic class is used then a Pydantic object will be returned.\n",
    "\n",
    "As a example, let's get a model to generate a joke and separate the setup from the punchline:"
   ],
   "id": "ce2acaa8f100897a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T07:29:41.608949Z",
     "start_time": "2024-09-16T07:29:41.311983Z"
    }
   },
   "source": [
    "import os\n",
    "import yaml\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "\n",
    "\n",
    "with open('../utils/config.yml', 'r') as stream:\n",
    "    zhipuai_api_key = yaml.safe_load(stream)['api_key']\n",
    "\n",
    "os.environ['ZHIPUAI_API_KEY'] = zhipuai_api_key\n",
    "\n",
    "chat_model = ChatZhipuAI(\n",
    "    model='glm-4-plus',\n",
    "    temperature=0,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pydantic class\n",
    "\n",
    "If we want the model to return a Pydantic object, we just need to pass in the desired Pydantic class. The key advantage of using Pydantic is that the model-generated output wil be validated. Pydantic will raise an error if any required fields are missing or if any fields are of the wrong type."
   ],
   "id": "9236d547f0cb93e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T07:29:43.351850Z",
     "start_time": "2024-09-16T07:29:41.609878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "#Pydantic\n",
    "class Joke(BaseModel):\n",
    "    '''Joke to tell user.'''\n",
    "    \n",
    "    setup: str = Field(description='The setup of the joke.')\n",
    "    punchline: str = Field(description='The punchline to the joke.')\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description='How funny the joke is, from 1 to 10.'\n",
    "    )\n",
    "    \n",
    "structured_llm = chat_model.with_structured_output(Joke)\n",
    "structured_llm.invoke('Tell me a joke about cats')"
   ],
   "id": "4f237ef4c77c81ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't cats play poker in the jungle?\", punchline='Too many cheetahs.', rating=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TypedDict or JSON Schema\n",
    "\n",
    "if you don't want to use Pydantic, explicitly don't want validation of the arguments, or want to be able to stream the model outputs, you can define your schema using a TypedDict class. We can optionally use a special `Annotated` syntax supported by LangChain that allows you to specify the default value and description of a field. the default value is *not* filled in automatically if the model doesn't generate it, it is only used in defining the schema that is passed to the model."
   ],
   "id": "40764a50230a7f06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T07:29:44.869572Z",
     "start_time": "2024-09-16T07:29:43.353686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    ''' Joke tell to the user.'''\n",
    "    \n",
    "    setup: Annotated[str, ..., 'The setup of the joke.']\n",
    "    \n",
    "    ''' Alternatively, we could have specified setup as :\n",
    "    \n",
    "    setup: str                      no default, no description\n",
    "    setup: Annotated[str,...]       no default, no description\n",
    "    setup: Annotated[str,'foo']     default, no description\n",
    "    '''\n",
    "    punchline: Annotated[str, ..., 'The punchline to the joke.']\n",
    "    rating: Annotated[Optional[int],None,'How funny the joke is, from 1 to 10.']\n",
    "    \n",
    "structured_llm = chat_model.with_structured_output(Joke)\n",
    "structured_llm.invoke('Tell me a joke about cats')"
   ],
   "id": "56c4c4804425421",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't cats play poker in the jungle?\",\n",
       " 'punchline': 'Too many cheetahs.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Equivalently, we can pass in a JSON Schema dict. This requires no imports or classes and makes it very clear exactly how each parameter is documented, at the cost of being a bit more verbose.",
   "id": "74fc598220a8d7f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T07:29:46.509700Z",
     "start_time": "2024-09-16T07:29:44.872205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_schmea = {\n",
    "    'title': 'joke',\n",
    "    'description': 'A joke to tell user.',\n",
    "    'type': 'object',\n",
    "    'properties': {\n",
    "        'setup':{\n",
    "            'type': 'string',\n",
    "            'description': 'The setup of the joke.',\n",
    "        },\n",
    "        'punchline':{\n",
    "            'type': 'string',\n",
    "            'description': 'The punchline to the joke.',\n",
    "        },\n",
    "        'rating':{\n",
    "            'type': 'integer',\n",
    "            'description': 'How funny the joke is, from 1 to 10.',\n",
    "            'default': None,\n",
    "        },\n",
    "    },\n",
    "    'required': ['setup', 'punchline','rating'],\n",
    "}\n",
    "\n",
    "structured_llm = chat_model.with_structured_output(json_schmea)\n",
    "structured_llm.invoke('Tell me a joke about cats')"
   ],
   "id": "dc45e0b460152d6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't cats play poker in the jungle?\",\n",
       " 'punchline': 'Too many cheetahs.',\n",
       " 'rating': 7}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Choosing between multiple schemas\n",
    "\n",
    "The simplest way to let the model choose from multiple schemas is to create a parent schema that has a Union-typed attribute:"
   ],
   "id": "841dea7f936b4332"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T07:29:48.244186Z",
     "start_time": "2024-09-16T07:29:46.511147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Union\n",
    "\n",
    "# Pydantic\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description='The setup of the joke.')\n",
    "    punchline: str = Field(description='The punchline to the joke.')\n",
    "    rating: Optional[int] = Field(\n",
    "        default=None, description='How funny the joke is, from 1 to 10.'\n",
    "    )\n",
    "    \n",
    "class ConversationResponse(BaseModel):\n",
    "    '''Respond in a conversational manner. Be kind and helpful.'''\n",
    "    \n",
    "    response: str = Field(description=\"A conversational response to the user's query\")\n",
    "    \n",
    "class Response(BaseModel):\n",
    "    output: Union[Joke, ConversationResponse]\n",
    "    \n",
    "structured_llm = chat_model.with_structured_output(Response)\n",
    "structured_llm.invoke('Tell me a joke about cats')"
   ],
   "id": "d47838aa33d72f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(output=Joke(setup=\"Why don't cats play poker in the jungle?\", punchline='Too many cheetahs.', rating=None))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T07:29:52.972431Z",
     "start_time": "2024-09-16T07:29:51.089053Z"
    }
   },
   "cell_type": "code",
   "source": "structured_llm.invoke('How are you?')",
   "id": "436d6c11df7720bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(output=ConversationResponse(response=\"I'm just a computer program, so I don't have feelings, but I'm ready and functioning properly! How can I assist you today?\"))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Streaming\n",
    "\n",
    "We can stream outputs from our structured model when the output type is a dict(i.e.,when the schema is specified as TypedDict class or JSON Schema dict)."
   ],
   "id": "893dacba915c7eff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T08:00:47.425941Z",
     "start_time": "2024-09-16T08:00:45.834765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "    \n",
    "    setup: Annotated[str, ..., 'The setup of the joke.']\n",
    "    punchline: Annotated[str, ..., 'The punchline to the joke.']\n",
    "    rating: Annotated[Optional[int],None,'How funny the joke is, from 1 to 10.']\n",
    "    \n",
    "structured_llm = chat_model.with_structured_output(Joke)\n",
    "for chunk in structured_llm.stream('Tell me a joke about dogs'):\n",
    "    print(chunk)"
   ],
   "id": "7a6a309f54b3e9bf",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Few-shot prompting\n",
    "\n",
    "For more complex schema it's very useful to add few-shot examples to the prompt. This can be done in a few ways. The simplest and most universal way is to add examples to a system message in the prompt:"
   ],
   "id": "780029be8ece18af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T08:08:41.973026Z",
     "start_time": "2024-09-16T08:08:39.758996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
    "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
    "\n",
    "Here are some examples of jokes:\n",
    "\n",
    "example_user: Tell me a joke about planes\n",
    "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
    "\n",
    "example_user: Tell me another joke about planes\n",
    "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
    "\n",
    "example_user: Now about caterpillars\n",
    "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
    "\n",
    "few_shot_structured_llm = prompt | structured_llm\n",
    "few_shot_structured_llm.invoke(\"what's something funny about woodpeckers\")"
   ],
   "id": "4d95dfd0d8f5994b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Woodpecker',\n",
       " 'punchline': \"Woodpecker knock-knock on trees, but they never get a 'who's there?'!\",\n",
       " 'rating': 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d521972605fa4f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
