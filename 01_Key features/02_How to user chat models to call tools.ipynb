{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How to use chat models to call tools\n",
    "\n",
    "Tool calling allows a chat model to respond to a given prompt by \"calling a tool\".\n",
    "\n",
    "Remember, while the name \"tool calling\" implies that the model is directly performing some action, this is actually not the case! The model only generates the arguments to a tool, and actually running the tool(or not) is up to the user.\n",
    "\n",
    "Tool calling is a general technique that generates structured output from a model, and you can use it even when you don't intend to invoke any tools. An example use-case of that is extraction from unstructured text.\n",
    "\n",
    "![img1](../asset/tool_call.png)\n",
    "\n",
    "LangChain implements standard interface for defining tools, passing them to LLMs, and representing tool calls. This guide will cover how to bind tools to an LLM, then invoke the LLM to generate these arguments.\n",
    "\n",
    "## Defining tool schemas\n",
    "\n",
    "For a model to be able to call tools, we need to pass in tool schemas that describe what the tool does and what it's arguments are. Chat models that support tool calling features implement a `.bind_tools()` method for passing tool schemas to the model. Tool schemas can be passed in as Python functions(with typehints and docstrings), Pydantic models, TypeDict classes, or LangChain Tool objects. Subsequent invocations of the model will pass in these tool schemas along with the prompt.\n",
    "\n",
    "\n",
    "\n",
    "## Python functions\n",
    "\n",
    "Our tool schemas can be Python functions:"
   ],
   "id": "2217cfa72fc3367f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The function name, type hints, and docstring are all part of the tool\n",
    "# schema that's passed to the model. Defining good, descriptive schemas\n",
    "# is an extension of prompt engineering and is an important part of \n",
    "# getting models to perform well.\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\" Add two integers.\n",
    "    \n",
    "    Args:\n",
    "        a: First integer.\n",
    "        b: Second integer.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "    \n",
    "    Args:\n",
    "        a: First integer.\n",
    "        b: Second integer. \n",
    "    \"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LangChain Tool\n",
    "\n",
    "LangChain also implements a `@tool` decorator that allows for further control of the tool schema, such as tool names and argument descriptions.\n",
    "\n",
    "## Pydantic class\n",
    "\n",
    "You can equivalently define the schemas without the accompanying functions using Pydantic.\n",
    "\n",
    "Note that all fields are `required` unless provided a default value.\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "4393b69871be2620"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T13:13:32.643930Z",
     "start_time": "2024-09-16T13:13:32.561651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    \n",
    "    a: int = Field(..., description=\"First integer.\")\n",
    "    b: int = Field(..., description=\"Second integer.\")\n",
    "    \n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    \n",
    "    a: int = Field(..., description=\"First integer.\")\n",
    "    b: int = Field(..., description=\"Second integer.\")"
   ],
   "id": "273e5af0cea579d1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TypedDict class\n",
    "\n",
    "Or using TypedDicts and annotations:"
   ],
   "id": "161a5c183e72b25a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T13:13:35.608304Z",
     "start_time": "2024-09-16T13:13:35.602939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class add(TypedDict):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    \n",
    "    # Annotations must have the type and can optionally include a default value and description\n",
    "    # (in that order)\n",
    "    \n",
    "    a: Annotated[int, ...,'First integer.']\n",
    "    b: Annotated[int, ...,'Second integer.']\n",
    "    \n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    \n",
    "    a: Annotated[int, ...,'First integer.']\n",
    "    b: Annotated[int, ...,'Second integer.']\n",
    "    \n",
    "tools = [add, multiply]"
   ],
   "id": "3b60bafc0c7939d6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To actually bind those schemas to a chat model, we'll use the `.bind_tools()` method. This handles converting the `add` and `multiply` schemas to the proper format for the model. The tool schema will then be passed it in each time the model is invoked.",
   "id": "3253a64d8940d31d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T13:13:38.925718Z",
     "start_time": "2024-09-16T13:13:38.596916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import yaml\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "\n",
    "\n",
    "with open('../utils/config.yml', 'r') as stream:\n",
    "    zhipuai_api_key = yaml.safe_load(stream)['api_key']\n",
    "\n",
    "os.environ['ZHIPUAI_API_KEY'] = zhipuai_api_key\n",
    "\n",
    "llm = ChatZhipuAI(\n",
    "    model='glm-4-plus',\n",
    "    temperature=0,\n",
    ")"
   ],
   "id": "2f73d9a2c0110b8f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T13:13:42.289987Z",
     "start_time": "2024-09-16T13:13:40.846702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "query = \"what's 3 * 12 ?\"\n",
    "llm_with_tools.invoke(query)"
   ],
   "id": "ef3bd47764b01e3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'id': 'call_9021294753560307203', 'index': 0, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 285, 'total_tokens': 300}, 'model_name': 'glm-4-plus', 'finish_reason': 'tool_calls'}, id='run-0a9c864c-bbf1-4073-b982-c9aac7b8d50a-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_9021294753560307203', 'type': 'tool_call'}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see our LLM generated arguments to a tool! You can look at the docs for bind_tools() to learn about all the ways to customize how your LLM selects tools, as well as this guide on how to force the LLM to call a tool rather than letting it decide.",
   "id": "e7d9bd1faa6d9cd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tool calls\n",
    "\n",
    "If tool calls are included in a LLM response, they are attached to the corresponding message or message chunk as a list of tool call objects in the `.tool_calls` attribute.\n",
    "\n",
    "Note that chat models can call multiple tools at once.\n",
    "\n",
    "A `ToolCall` is typed dict that includes a tool name, dict of argument values, and(optionally) and identifier. Message with no tool calls default to an empty list for this attribute."
   ],
   "id": "9b034ad9c2aa7672"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T13:33:35.076600Z",
     "start_time": "2024-09-16T13:33:33.264990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"what's 3 * 12 ? Also, what is 11 + 49?\"\n",
    "llm_with_tools.invoke(query).tool_calls"
   ],
   "id": "f00213d244dfc2ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'call_9021299563924013477',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': 'call_9021299563924013478',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The `.tool_calls` attribute should contain valid tool calls. Note that on occasion, model provides may output malformed tool calls(e.g.,arguments that are not valid JSON). When parsing fails in these cases, instances of InvalidToolCall are populated in the `.invalid_tool_calls` attribute. An `InvalidToolCall` can have a name, string arguments, identifier, and error message.",
   "id": "9f6dbe4281295bf0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parsing\n",
    "\n",
    "If desired, output parsers can further process the output. For example, we can convert existing values populated on the `tool_calls` to Pydantic objects using the PydanticToolsParser:"
   ],
   "id": "df7d35d0981aa13b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T13:46:34.646518Z",
     "start_time": "2024-09-16T13:46:33.014914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import PydanticToolsParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "\n",
    "chain = llm_with_tools | PydanticToolsParser(tools=[add, multiply])\n",
    "chain.invoke(query)"
   ],
   "id": "480fb5eb8d339a09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[multiply(a=3, b=12), add(a=11, b=49)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
